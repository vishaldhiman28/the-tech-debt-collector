# Complete Project Setup Guide

## ğŸ“¦ Prerequisites

```bash
# Install Docker & Docker Compose
brew install docker docker-compose

# Install Go 1.21+
brew install go

# API Keys needed
export OPENAI_API_KEY=sk-...
export CLAUDE_API_KEY=claude-...  # Optional
```

## ğŸš€ Quick Start (Docker)

### 1. Start Full Stack

```bash
cd "/Users/yaegar/Tech debt collector"

# Set environment variables
export OPENAI_API_KEY=sk-your-key

# Start all services
docker-compose up -d
```

### 2. Access Services

```
- Tech Debt Collector API: Runs on demand
- Qdrant Vector DB: http://localhost:6333
- Prometheus Metrics: http://localhost:9090
- Grafana Dashboards: http://localhost:3000 (admin/admin)
- Feedback Dashboard: http://localhost:8080
```

### 3. Run Analysis

```bash
docker-compose exec collector ./tech-debt-collector \
  -path /workspace \
  -agent -rag \
  -format json \
  -output report.json
```

## ğŸ› ï¸ Local Development (Without Docker)

### 1. Install Dependencies

```bash
cd "/Users/yaegar/Tech debt collector"
go mod download
go mod tidy
```

### 2. Start Qdrant Locally

```bash
docker run -p 6333:6333 qdrant/qdrant:latest
```

### 3. Start Prometheus

```bash
# Download prometheus first
brew install prometheus

# Run with config
prometheus --config.file=observability/prometheus.yml
```

### 4. Build Binary

```bash
make build
# or
go build -o bin/tech-debt-collector ./cmd/tech-debt-collector
```

### 5. Run Analysis

```bash
./bin/tech-debt-collector \
  -path ./test_repo \
  -agent -rag \
  -verbose

# With Grafana dashboard
open http://localhost:3000
```

## ğŸ§ª Running Tests

```bash
# Run all tests
go test ./...

# With coverage
go test -cover ./...

# Specific package
go test -v ./internal/detector
go test -v ./internal/scorer
go test -v ./internal/agent
```

### Expected Coverage

```
detector: 80%+
scorer: 85%+
agent: 75%+
rag: 70%+
```

## ğŸ“Š Monitoring

### Prometheus Metrics

Endpoint: `http://localhost:9090`

Available metrics:
- `tech_debt_items_scanned_total` - Total items scanned
- `tech_debt_items_analyzed_total` - Items analyzed by LLM
- `tech_debt_llm_latency_ms` - LLM response time
- `tech_debt_llm_cost_usd` - Cumulative LLM cost
- `tech_debt_vector_searches_total` - RAG searches
- `tech_debt_accuracy` - Analysis accuracy
- `tech_debt_fixed_rate` - Items actually fixed

### Grafana Dashboards

Endpoint: `http://localhost:3000`

Pre-configured dashboards:
- Analysis Performance (latency, cost, accuracy)
- LLM Model Comparison (GPT-4 vs Claude vs local)
- RAG Effectiveness (search latency, results quality)
- Feedback Trends (rating progression, user satisfaction)

## ğŸ¯ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Tech Debt Collector                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚  Scanner          Detector          Scorer              â”‚
â”‚  (Files)    â†’    (Comments)   â†’    (Risk)    â†’          â”‚
â”‚                                                           â”‚
â”‚                         â†“                                 â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚           Agent (5-Step Reasoning)           â”‚       â”‚
â”‚  â”‚                                              â”‚       â”‚
â”‚  â”‚  Step 1: RAG Search  (Vector Similarity)    â”‚       â”‚
â”‚  â”‚  Step 2: LLM Analysis (Initial Assessment) â”‚       â”‚
â”‚  â”‚  Step 3: Confidence Check                   â”‚       â”‚
â”‚  â”‚  Step 4: Refinement (if needed)            â”‚       â”‚
â”‚  â”‚  Step 5: Finalize & Report                  â”‚       â”‚
â”‚  â”‚                                              â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â†“                              â†“                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚    â”‚ Qdrant VDB  â”‚              â”‚ Multi-Model  â”‚       â”‚
â”‚    â”‚ (RAG)       â”‚              â”‚ AI Backend   â”‚       â”‚
â”‚    â”‚             â”‚              â”‚ (GPT/Claude) â”‚       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                           â”‚
â”‚                         â†“                                 â”‚
â”‚                                                           â”‚
â”‚              Feedback â†’ Learning Loop                     â”‚
â”‚              (Continuous Improvement)                     â”‚
â”‚                                                           â”‚
â”‚                    Report Output                          â”‚
â”‚              (JSON, Text, Dashboard)                      â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â†“
    
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Observability Stack                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                              â”‚
â”‚  Prometheus (Metrics)                       â”‚
â”‚  Grafana (Dashboards)                       â”‚
â”‚  Structured Logging (slog)                  â”‚
â”‚  OpenTelemetry (Distributed Tracing)        â”‚
â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Web Dashboard                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                              â”‚
â”‚  Feedback Collection                        â”‚
â”‚  Trend Analysis                             â”‚
â”‚  Misclassification Reporting                â”‚
â”‚  Model Performance Tracking                 â”‚
â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”‘ Configuration

### Environment Variables

```bash
# Required
export OPENAI_API_KEY=sk-...

# Optional
export CLAUDE_API_KEY=claude-...
export QDRANT_URL=http://localhost:6333
export QDRANT_API_KEY=tech-debt-secret
export PROMETHEUS_PUSHGATEWAY=http://localhost:9091
export LOG_LEVEL=info
```

### CLI Flags

```bash
tech-debt-collector \
  -path ./repo              # Repository to scan
  -output report.json       # Output file
  -format json              # json, text
  -agent                    # Enable agentic analysis
  -rag                      # Enable RAG
  -claude                   # Use Claude instead of GPT
  -verbose                  # Verbose logging
  -qdrant-url URL          # Qdrant connection
```

## ğŸ“ˆ Performance Targets

| Component | Metric | Target |
|-----------|--------|--------|
| Scanner | 10K files/min | âœ“ |
| Detector | 1K files/min | âœ“ |
| Scorer | Instant | âœ“ |
| Agent (top 10) | 30s | âœ“ |
| RAG Search | <100ms | âœ“ |
| LLM Request | <5s | âœ“ |
| Total Run | <2min | âœ“ |
| Cost (per run) | <$1 | âœ“ |

## ğŸš¨ Troubleshooting

### Qdrant Connection Failed

```bash
# Check if Qdrant is running
curl http://localhost:6333/health

# Restart Qdrant
docker-compose restart qdrant
```

### LLM API Errors

```bash
# Verify API key
echo $OPENAI_API_KEY

# Test OpenAI connection
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
  https://api.openai.com/v1/models
```

### Memory Issues

```bash
# Increase Docker memory
docker-compose down
export DOCKER_MEMORY=4g
docker-compose up -d
```

## ğŸ“š Code Structure

```
tech-debt-collector/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ tech-debt-collector/     # Main CLI entry point
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ models/                  # Data structures
â”‚   â”œâ”€â”€ scanner/                 # Repository scanning
â”‚   â”œâ”€â”€ detector/                # Debt detection
â”‚   â”œâ”€â”€ scorer/                  # Risk scoring
â”‚   â”œâ”€â”€ ai/                      # LLM backends (multi-model)
â”‚   â”œâ”€â”€ rag/                     # Vector database & RAG
â”‚   â”œâ”€â”€ agent/                   # Agentic reasoning loop
â”‚   â”œâ”€â”€ feedback/                # Feedback collection
â”‚   â””â”€â”€ observability/           # Metrics & logging
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ main.go                  # Dashboard API
â”‚   â””â”€â”€ static/index.html        # Frontend UI
â”œâ”€â”€ observability/               # Prometheus & Grafana configs
â”œâ”€â”€ tests/                       # Unit & integration tests
â”œâ”€â”€ Dockerfile                   # Container image
â”œâ”€â”€ docker-compose.yml           # Full stack setup
â”œâ”€â”€ go.mod                       # Dependencies
â””â”€â”€ README.md
```

## ğŸ“ Interview Talking Points

**Q: Why this architecture?**
> Multi-step reasoning agent reduces hallucinations. RAG provides codebase context. Feedback loop enables continuous learning. Cost-optimized through smart model routing.

**Q: How does RAG help?**
> Semantic search finds similar debt in THIS codebase. Reduces generic advice, provides project-specific insights. Dramatically improves explanation quality.

**Q: Scalability?**
> Async processing with job queues. Distributed RAG with managed vector DB. Horizontal scaling of agent workers. Cost controls per-analysis.

**Q: Production readiness?**
> Full observability stack (Prometheus + Grafana). Error handling & fallbacks. Rate limiting. Structured logging. Comprehensive testing (80%+ coverage).

## ğŸ“ Next Steps

1. **Fine-tune prompts** based on feedback trends
2. **Add more tools** (git blame, test coverage, metrics)
3. **Implement distributed agent** (multiple workers)
4. **Add model fine-tuning** pipeline
5. **Deploy to Kubernetes** with GitOps
6. **Create Slack integration** for notifications

---

**Ready to impress senior engineers with your AI architecture!** ğŸš€
